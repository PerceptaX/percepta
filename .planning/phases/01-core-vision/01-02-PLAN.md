---
phase: 01-core-vision
plan: 02
type: execute
---

<objective>
Implement Claude Vision driver and camera capture for hardware observation.

Purpose: Build the perception engine - capture webcam frames and send to Claude Vision API for structured signal extraction. This is the core differentiator.

Output: Working VisionDriver that captures frames, sends to Claude Sonnet 4.5, parses LED/Display/Boot signals with 95%+ accuracy.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-vision/DISCOVERY.md
@.planning/phases/01-core-vision/01-01-SUMMARY.md

**Tech stack from Plan 1:**
- Core types: Signal interface, LEDSignal, DisplaySignal, BootTimingSignal, Observation
- SQLite storage driver functional

**New dependencies (from DISCOVERY):**
- `github.com/anthropics/anthropic-sdk-go` v1.22.1 - Claude Vision API
- `github.com/blackjack/webcam` - Linux V4L2 camera capture (behind CameraDriver interface)

**Key constraints:**
- Must achieve 95%+ accuracy on LED/display/boot signals
- Vision API response is unstructured text - parse with regex
- Parser must be isolated and swappable (will likely replace with structured output later)
- Camera implementation must be behind CameraDriver interface (platform-agnostic)
- API key from environment variable ANTHROPIC_API_KEY
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Linux V4L2 camera driver behind interface</name>
  <files>internal/camera/v4l2.go</files>
  <action>
Install dependency:
```bash
go get github.com/blackjack/webcam@latest
```

Create `internal/camera/v4l2.go` implementing core.CameraDriver interface:

```go
package camera

import (
    "fmt"
    "github.com/blackjack/webcam"
    "github.com/perceptumx/percepta/internal/core"
)

// V4L2Camera implements core.CameraDriver for Linux V4L2 devices
type V4L2Camera struct {
    devicePath string
    cam        *webcam.Webcam
}

// NewV4L2Camera creates a new Linux V4L2 camera driver
func NewV4L2Camera(devicePath string) core.CameraDriver {
    return &V4L2Camera{devicePath: devicePath}
}

func (c *V4L2Camera) Open() error {
    cam, err := webcam.Open(c.devicePath)
    if err != nil {
        return fmt.Errorf("failed to open camera %s: %w", c.devicePath, err)
    }
    c.cam = cam

    // Set format to MJPEG 1280x720 (balance quality vs size)
    format := webcam.PixelFormat(webcam.V4L2_PIX_FMT_MJPEG)
    _, _, _, err = c.cam.SetImageFormat(format, 1280, 720)
    if err != nil {
        c.cam.Close()
        return fmt.Errorf("failed to set image format: %w", err)
    }

    // Start streaming
    err = c.cam.StartStreaming()
    if err != nil {
        c.cam.Close()
        return fmt.Errorf("failed to start streaming: %w", err)
    }

    return nil
}

func (c *V4L2Camera) CaptureFrame() ([]byte, error) {
    if c.cam == nil {
        return nil, fmt.Errorf("camera not opened")
    }

    // Wait for frame (5 second timeout)
    err := c.cam.WaitForFrame(5)
    if err != nil {
        return nil, fmt.Errorf("timeout waiting for frame: %w", err)
    }

    frame, err := c.cam.ReadFrame()
    if err != nil {
        return nil, fmt.Errorf("failed to read frame: %w", err)
    }

    // Return JPEG bytes (MJPEG is already JPEG frames)
    return frame, nil
}

func (c *V4L2Camera) Close() error {
    if c.cam != nil {
        c.cam.StopStreaming()
        return c.cam.Close()
    }
    return nil
}
```

Implements core.CameraDriver interface. Returns JPEG bytes (platform-agnostic format). Linux-specific implementation in internal/camera package. Future: Add internal/camera/avfoundation.go for macOS, internal/camera/mf.go for Windows. Core types never see platform-specific APIs.
  </action>
  <verify>
- `go build ./internal/camera` succeeds
- Verify /dev/video0 exists on system: `ls /dev/video0`
- If available, test: Open camera, capture frame, verify frame is non-empty JPEG bytes
- Verify implements core.CameraDriver interface
  </verify>
  <done>Linux V4L2 camera driver implemented behind core.CameraDriver interface. Platform-specific code isolated. Returns platform-agnostic JPEG bytes.</done>
</task>

<task type="auto">
  <name>Task 2: Implement Claude Vision driver with isolated parser</name>
  <files>internal/vision/claude.go, internal/vision/parser.go</files>
  <action>
Install Anthropic SDK:
```bash
go get github.com/anthropics/anthropic-sdk-go@v1.22.1
```

Create `internal/vision/claude.go` implementing core.VisionDriver interface:

```go
package vision

import (
    "context"
    "encoding/base64"
    "fmt"
    "os"
    "time"

    "github.com/anthropics/anthropic-sdk-go"
    "github.com/anthropics/anthropic-sdk-go/option"
    "github.com/perceptumx/percepta/internal/core"
)

const HardwarePrompt = `Describe this embedded hardware device precisely.

Focus on:
1. LED states (on/off, color, blinking frequency in Hz)
2. Display content (transcribe ALL visible text exactly)
3. Boot sequence indicators if visible

Format your response as:
LEDs:
- [name/color]: [on/off], [color if visible], [frequency in Hz if blinking]

Displays:
- [type]: "[exact text shown]"

Boot: [duration in seconds if measurable]

Be precise with measurements. Estimate blink frequency in Hz.`

// ClaudeVision implements core.VisionDriver using Claude Sonnet 4.5
type ClaudeVision struct {
    client *anthropic.Client
    parser SignalParser
}

// SignalParser converts vision API response text to structured signals
// Isolated for easy replacement (regex now, structured output later)
type SignalParser interface {
    Parse(responseText string) []core.Signal
}

func NewClaudeVision() (*ClaudeVision, error) {
    apiKey := os.Getenv("ANTHROPIC_API_KEY")
    if apiKey == "" {
        return nil, fmt.Errorf("ANTHROPIC_API_KEY not set")
    }

    client := anthropic.NewClient(option.WithAPIKey(apiKey))

    return &ClaudeVision{
        client: client,
        parser: NewRegexParser(),  // Swappable parser
    }, nil
}

func (v *ClaudeVision) Observe(deviceID string, frame []byte) (*core.Observation, error) {
    // Encode to base64
    base64Frame := base64.StdEncoding.EncodeToString(frame)

    // Call Claude Vision API
    message, err := v.client.Messages.New(context.Background(), anthropic.MessageNewParams{
        MaxTokens: 1024,
        Model:     anthropic.ModelClaudeSonnet4_5_20250929,
        Messages: []anthropic.MessageParam{
            anthropic.NewUserMessage(
                anthropic.NewImageBlockFromBase64("image/jpeg", base64Frame),
                anthropic.NewTextBlock(HardwarePrompt),
            ),
        },
    })

    if err != nil {
        return nil, fmt.Errorf("vision API call failed: %w", err)
    }

    // Extract text response
    responseText := ""
    for _, block := range message.Content {
        if block.Type == "text" {
            responseText += block.Text
        }
    }

    // Parse signals using isolated parser
    signals := v.parser.Parse(responseText)

    return &core.Observation{
        ID:        core.GenerateID(),
        DeviceID:  deviceID,
        Timestamp: time.Now(),
        Signals:   signals,
    }, nil
}
```

Create `internal/vision/parser.go` with isolated regex parsing:

```go
package vision

import (
    "regexp"
    "strconv"
    "strings"
    "github.com/perceptumx/percepta/internal/core"
)

// RegexParser uses regex to extract signals from unstructured text
// This is a temporary MVP implementation - will be replaced with structured output
type RegexParser struct{}

func NewRegexParser() *RegexParser {
    return &RegexParser{}
}

func (p *RegexParser) Parse(text string) []core.Signal {
    var signals []core.Signal

    // Parse LED signals
    ledRegex := regexp.MustCompile(`(?i)([a-z0-9_-]+)?\s*(LED|led)(?:[^.]*)(on|off|blinking)(?:[^.]*?)(?:(\d+(?:\.\d+)?)\s*Hz)?`)
    ledMatches := ledRegex.FindAllStringSubmatch(text, -1)

    for _, match := range ledMatches {
        name := match[1]
        if name == "" {
            name = "UNKNOWN"
        }
        stateStr := strings.ToLower(match[3])

        led := core.LEDSignal{
            Name:       name,
            On:         stateStr == "on" || stateStr == "blinking",
            Confidence: 0.85,
        }

        if match[4] != "" {
            if freq, err := strconv.ParseFloat(match[4], 64); err == nil {
                led.BlinkHz = freq
            }
        }

        // Extract color from surrounding text
        colors := []string{"red", "green", "blue", "yellow", "white", "orange"}
        for _, color := range colors {
            if strings.Contains(strings.ToLower(text), color) {
                switch color {
                case "red":
                    led.Color = core.RGB{R: 255, G: 0, B: 0}
                case "green":
                    led.Color = core.RGB{R: 0, G: 255, B: 0}
                case "blue":
                    led.Color = core.RGB{R: 0, G: 0, B: 255}
                }
                break
            }
        }

        signals = append(signals, led)
    }

    // Parse Display signals
    displayRegex := regexp.MustCompile(`(?i)(OLED|LCD|Display)(?:[^"]*)"([^"]+)"`)
    displayMatches := displayRegex.FindAllStringSubmatch(text, -1)

    for _, match := range displayMatches {
        signals = append(signals, core.DisplaySignal{
            Name:       match[1],
            Text:       match[2],
            Confidence: 0.90,
        })
    }

    return signals
}
```

Parser isolated behind SignalParser interface. VisionDriver receives frame bytes (not camera object). ClaudeVision does NOT own camera - separation of concerns. Parser is swappable - future: replace with structured output prompting or tool use.
  </action>
  <verify>
- `go build ./internal/vision` succeeds
- Verify ClaudeVision implements core.VisionDriver interface
- Verify RegexParser implements SignalParser interface
- Test: Pass mock JPEG + Vision API response, verify parsed signals
  </verify>
  <done>Claude Vision driver implemented with isolated, swappable parser. VisionDriver accepts frame bytes (platform-agnostic). Parser cleanly replaceable with structured output later.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `go build ./...` succeeds
- [ ] Camera driver can open /dev/video0, capture JPEG frame
- [ ] Claude Vision driver accepts deviceID, returns Observation
- [ ] Vision response parsed into LEDSignal/DisplaySignal structs
- [ ] Observation includes ID, DeviceID, Timestamp, Signals
- [ ] No hardcoded API keys (uses ANTHROPIC_API_KEY env var)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Camera driver functional (Linux V4L2)
- Claude Vision integration working with Sonnet 4.5
- Signal parsing extracts LED/Display data from unstructured text
- End-to-end: camera frame → Vision API → structured Observation
  </success_criteria>

<output>
After completion, create `.planning/phases/01-core-vision/01-02-SUMMARY.md`:

# Phase 1 Plan 2: Vision Engine Summary

**Claude Vision driver and camera capture operational for hardware perception**

## Accomplishments

- Linux V4L2 camera driver implemented behind core.CameraDriver interface
- MJPEG 1280x720 capture with proper device cleanup
- Claude Vision API integration with Anthropic SDK v1.22.1 behind core.VisionDriver interface
- Signal parser isolated behind SignalParser interface (regex for MVP, swappable)
- Platform-agnostic architecture: camera returns JPEG bytes, vision accepts bytes

## Files Created/Modified

- `internal/camera/v4l2.go` - Linux V4L2 implementation of core.CameraDriver
- `internal/vision/claude.go` - Claude Vision implementation of core.VisionDriver
- `internal/vision/parser.go` - Isolated regex signal parser (RegexParser)

## Decisions Made

- **Camera behind interface**: V4L2 implementation in internal/camera. Future: Add avfoundation.go (macOS), mf.go (Windows) without refactor.
- **Vision accepts frame bytes**: Platform-agnostic. No coupling to specific camera API.
- **Parser isolation**: SignalParser interface allows clean swap to structured output prompting later.
- **Regex for MVP**: Sufficient for LED/Display extraction. Will replace with tool use when structured output is reliable.

## Issues Encountered

(Note any camera access issues, Vision API rate limits, or parsing edge cases discovered during testing)

## Next Phase Readiness

Ready for 01-03: CLI observe command. Can now capture hardware state and convert to structured observations.
</output>
