---
phase: 02-assertions
plan: 02
type: execute
---

<objective>
Implement CLI assert command with formatted result output.

Purpose: Enable users to run `percepta assert <device> <dsl>` to validate hardware state against expectations. This completes Phase 2's goal of deterministic behavior validation.

Output: Working `percepta assert` command that captures observation, evaluates assertion, and displays pass/fail result with details.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-assertions/02-01-SUMMARY.md

**Tech stack available:**
- Cobra CLI framework (from Phase 1)
- Core API with Observe() method
- Assertion types and DSL parser (from 02-01)
- Human-readable output patterns (from observe command)

**Key files from prior work:**
@cmd/percepta/main.go
@cmd/percepta/observe.go
@internal/assertions/types.go
@internal/assertions/parser.go
@pkg/percepta/percepta.go

**Constraining decisions:**
- Human-readable output (not JSON) - consistent with observe command
- Single assertion per invocation (not batch mode in MVP)
- Observation captured immediately before evaluation (not from history)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create assert CLI command</name>
  <files>cmd/percepta/assert.go, cmd/percepta/main.go</files>
  <action>
Create `cmd/percepta/assert.go`:

```go
package main

import (
	"fmt"
	"os"

	"github.com/perceptumx/percepta/internal/assertions"
	"github.com/perceptumx/percepta/internal/config"
	"github.com/perceptumx/percepta/pkg/percepta"
	"github.com/spf13/cobra"
)

var assertCmd = &cobra.Command{
	Use:   "assert <device> <assertion>",
	Short: "Validate hardware state against expected behavior",
	Long:  "Captures observation and evaluates assertion. Returns 0 if passed, 1 if failed.",
	Args:  cobra.ExactArgs(2),
	RunE:  runAssert,
}

func runAssert(cmd *cobra.Command, args []string) error {
	deviceID := args[0]
	assertionDSL := args[1]

	// Parse assertion DSL
	assertion, err := assertions.Parse(assertionDSL)
	if err != nil {
		return fmt.Errorf("invalid assertion: %w", err)
	}

	// Load config and initialize Core
	cfg, err := config.Load()
	if err != nil {
		return fmt.Errorf("config load failed: %w", err)
	}

	cameraPath := "/dev/video0"
	if deviceCfg, ok := cfg.Devices[deviceID]; ok {
		if deviceCfg.CameraID != "" {
			cameraPath = deviceCfg.CameraID
		}
	}

	perceptaCore, err := percepta.NewCore(cameraPath)
	if err != nil {
		return err
	}

	// Capture observation
	fmt.Fprintf(os.Stderr, "Observing %s (evaluating assertion)...\n", deviceID)
	obs, err := perceptaCore.Observe(deviceID)
	if err != nil {
		return err
	}

	// Evaluate assertion
	result := assertion.Evaluate(obs)

	// Format and print result
	printAssertionResult(assertion, result)

	// Exit with appropriate code
	if !result.Passed {
		os.Exit(1)
	}

	return nil
}
```

Update `cmd/percepta/main.go` to add assertCmd to rootCmd in init().

Assertion evaluation flow:
1. Parse DSL → Assertion
2. Capture observation (same as observe command)
3. Evaluate assertion against observation
4. Print result
5. Exit 0 (pass) or 1 (fail)
  </action>
  <verify>
- go build ./cmd/percepta succeeds
- ./percepta assert --help shows usage
- Command accepts two arguments (device and assertion)
  </verify>
  <done>Assert command registered in Cobra, accepts device and assertion DSL, returns exit code based on pass/fail</done>
</task>

<task type="auto">
  <name>Task 2: Implement assertion result formatting</name>
  <files>cmd/percepta/assert.go</files>
  <action>
Add printAssertionResult function to assert.go:

```go
func printAssertionResult(assertion assertions.Assertion, result assertions.AssertionResult) {
	// Header with pass/fail indicator
	if result.Passed {
		fmt.Printf("✅ PASS: %s\n", assertion.String())
	} else {
		fmt.Printf("❌ FAIL: %s\n", assertion.String())
	}

	// Details section
	fmt.Printf("\nExpected: %s\n", result.Expected)
	fmt.Printf("Actual:   %s\n", result.Actual)

	// Confidence indicator
	fmt.Printf("Confidence: %.2f\n", result.Confidence)

	// Additional message if present
	if result.Message != "" {
		fmt.Printf("\nDetails: %s\n", result.Message)
	}
}
```

Output format:
- **Pass**: ✅ PASS with green checkmark, shows expected = actual
- **Fail**: ❌ FAIL with red X, shows expected vs actual mismatch
- **Confidence**: Display signal confidence (for transparency)
- **Message**: Additional context (e.g., "LED 'power' not found in observation")

Exit codes:
- 0 = assertion passed
- 1 = assertion failed
- 2 = error (parse failure, camera failure, etc.) - handled by cobra error handling
  </action>
  <verify>
- go build ./cmd/percepta succeeds
- Output includes PASS/FAIL indicator
- Expected and Actual values displayed
- Confidence score shown
  </verify>
  <done>Assertion results formatted with clear pass/fail indicator, expected vs actual comparison, confidence score, and descriptive messages</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `go build ./cmd/percepta` succeeds
- [ ] `./percepta assert --help` shows usage
- [ ] Assert command captures observation and evaluates assertion
- [ ] Pass result displays ✅ and exits 0
- [ ] Fail result displays ❌ and exits 1
- [ ] Output is human-readable and clear
- [ ] Phase 2 goal met: `percepta assert <device> <dsl>` validates behavior deterministically
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No build errors
- Assert command functional end-to-end
- Exit codes correct (0 = pass, 1 = fail)
- Output format consistent with observe command style
- **Phase 2 complete**: percepta assert validates hardware state against DSL expectations
  </success_criteria>

<output>
After completion, create `.planning/phases/02-assertions/02-02-SUMMARY.md`:

# Phase 2 Plan 2: Assert Command Summary

**CLI assert command operational - Phase 2 complete**

## Accomplishments

- Assert CLI command with device and DSL arguments
- Formatted output with PASS/FAIL indicators
- Exit code handling (0 = pass, 1 = fail)
- End-to-end flow: parse DSL → observe → evaluate → report
- Human-readable output consistent with observe command

## Files Created/Modified

- `cmd/percepta/assert.go` - Assert command implementation
- `cmd/percepta/main.go` - Register assert command

## Decisions Made

[Key decisions and rationale, or "None - followed plan"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

**Phase 2 complete! Ready for Phase 3: Diff + Firmware Tracking.**

Phase 2 delivered:
- ✅ DSL parser for LED/Display/Timing assertions
- ✅ Assertion evaluation engine
- ✅ percepta assert <device> <dsl> working end-to-end
- ✅ Deterministic validation with confidence scores
- ✅ Clear pass/fail reporting with exit codes

Success criteria: Assertions validate observed behavior deterministically. Ready to add firmware tracking and diff capabilities in Phase 3.
</output>
